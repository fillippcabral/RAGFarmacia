import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains.retrieval_qa.base import RetrievalQA

# === 1. Configura√ß√£o inicial ===
load_dotenv()
st.set_page_config(page_title="üî¨ Consulta de medicamentos", layout="wide")

pdf_file = st.file_uploader("üìÑ Envie o documento do medicamento com os lotes com o Manual de uso (PDF ou CSV)", type=["pdf", "csv"])

if pdf_file:
    # Cria diret√≥rio tempor√°rio para salvar o PDF
    os.makedirs("docs", exist_ok=True)
    pdf_path = os.path.join("docs", pdf_file.name)

    with open(pdf_path, "wb") as f:
        f.write(pdf_file.read())

    st.info("üìò Extraindo conte√∫do do PDF...")

    try:
        loader = PyMuPDFLoader(pdf_path)
        documents = loader.load()
    except Exception as e:
        st.error(f"Erro ao ler o PDF: {e}")
        st.stop()

    # === 4. Fragmenta√ß√£o do texto ===
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    split_docs = splitter.split_documents(documents)

    # === 5. Cria√ß√£o dos embeddings ===
    embeddings = OpenAIEmbeddings(openai_api_key=openai_key)

    # === 6. Banco vetorial (FAISS) ===
    vectorstore = FAISS.from_documents(split_docs, embeddings)
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})

    # === 7. Configura√ß√£o do modelo de linguagem ===
    llm = ChatOpenAI(
        api_key=openai_key,
        model="gpt-4o-mini",  # Modelo moderno, r√°pido e econ√¥mico
        temperature=0.2
    )

    # === 8. Cria√ß√£o da cadeia RAG ===
    rag_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True
    )

    st.success("‚úÖ Medicamento processado e indexado com sucesso!")

    # === 9. Interface de Perguntas ===
    st.subheader("ü©∫ Pergunte sobre o medicamento")
    user_question = st.text_input("‚ùì Digite sua pergunta:")

    if user_question:
        with st.spinner("üîé Analisando os resultados com IA..."):
            resposta = rag_chain.invoke({"query": user_question})

        st.markdown("### üß† Resposta da IA:")
        st.markdown(resposta["result"])

        # Exibe as fontes de refer√™ncia do texto
        with st.expander("üìö Fontes de contexto utilizadas"):
            for i, doc in enumerate(resposta["source_documents"], start=1):
                st.markdown(f"**Trecho {i}:** {doc.page_content[:300]}...")
